# Hexastat_simpleQ
Finding best policy for Maplestory Hexastat enhancement


- 강화 방법에 대한 설명

  
총 20회의 강화를 시도할 수 있다.

강화는 최대 10번까지 성공할 수 있다. 

지금까지 강화가 성공한 횟수에 따라 강화 성공 확률과, 강화 비용이 변한다.

강화 성공 횟수에 따른 강화 확률은 다음과 같다. [0.35,0.35,0.35,0.2,0.2,0.2,0.2,0.15,0.1,0.05]

ex) 지금까지 강화가 0회 성공했을 경우, 이번 강화 성공 확률은 35%.

지금까지 강화가 9회 성공했을 경우, 이번 강화 성공 확률은 5%.
    
강화 성공 횟수에 따른 강화 비용은 다음과 같다. [-10, -10, -10, -20, -20, -20, -20, -30, -30, -50]

ex) 지금까지 강화가 0회 성공했을 경우, 이번 강화 비용 10원.

지금까지 강화가 9회 성공했을 경우, 이번 강화 비용 50원.
    
강화를 10회 시도했을 때 부터, 강화 단계를 초기화하고 처음부터 다시 강화할 수 있다. (이 때 초기화 비용은 무료이다.)

ex) 강화 성공을 8번 하는 것이 목표인데, 현재 11번 강화를 시도하여 1번 성공하였다. 20번 강화를 시도할 때까지 8번을 성공하지 못할 것 같으므로, 지금까지 강화한 것을 초기화하고, 0번 강화 시도 0번 성공 상태로 되돌린다.


- 풀고 싶은 문제
  

내가 목표로 하는 강화 성공 수치가 있을 때, 언제 강화를 초기화 하는 것이 가장 비용을 적게 들이고 내 목표를 이룰 수 있을까?

ex) 목표치: 8회 강화 성공

n회 강화를 시도하고 m번 성공했을 경우 과연 초기화하고 강화를 새로 하는 것이 이득일까, 강화를 계속 진행하는 것이 이득일까를 판별.


-학습 방법


Q학습을 이용하여 학습을 진행한다. 소모한 돈을 reward로 설정하여, reward가 최대가 되는(즉, 소모한 돈이 최소가 되는) 방향으로 학습이 진행된다.

강화를 10회 시도할때까지는, 강화를 초기화 할 수 없기 때문에, Q table은 10회 강화 ~ 20회 강화 시도까지만 표기되도록 구성하였다.

Q table을 작성하여, 길찾기의 학습과 같은 방법으로 학습을 진행하였고, 학습 결과는 Q_table_action_zero.txt, Q_table_action_one.txt 파일에 저장된다.

현재 업로드된 두 txt파일은, 8회 성공을 목표로 학습을 진행했을 때, 학습이 완료된 상태의 Q table이다.


-결과


8회 성공을 목표로 학습을 진행하면 다음의 결과가 나온다. (0은 현 강화 상태를 초기화하라는 뜻이고, 1은 강화를 계속 시도하라는 뜻이다.)

![result](https://github.com/baesh/Hexastat_simpleQ/assets/18441461/573289ff-a035-4e3d-b6df-9378047eed27)

이때, 행은 같은 시도 횟수의 경우끼리 묶여 있고, 열은 같은 성공 횟수끼리 묶여 있다.

ex) 

    1행 2열의 데이터가 0이라는 의미는 10회 강화를 시도하여, 1번 성공했을 경우, 강화 단계를 초기화하라는 뜻이다.

    3행 5열의 데이터가 1이라는 의미는 12회 강화를 시도하여, 4번 성공했을 경우, 강화 단계를 초기화지 않고 강화를 계속 진행하라는 뜻이다.


즉, 

    10회까지 강화를 진행했을 때, 성공 횟수가 4회 미만이면 강화 단계를 초기화,

    14회까지 강화를 진행했을 때, 성공 횟수가 5회 미만이면 강화 단계를 초기화,

    17회까지 강화를 진행했을 때, 성공 횟수가 6회 미만이면 강화 단계를 초기화,

    19회까지 강화를 진행했을 때, 성공 횟수가 7회 미만이면 강화 단계를 초기화하면 된다.
